import { Howl } from 'howler'
import { AudioConfig } from '@/types'

class AudioService {
  private config: AudioConfig = {
    enabled: true,
    volume: 1.0,
    voiceType: 'female',
    backgroundMusic: 1, // ê¸°ë³¸ ë°°ê²½ìŒì•… 1ë²ˆ
  }

  private sounds: Map<string, Howl> = new Map()
  private backgroundMusic: Howl | null = null
  private backgroundMusicId: number | null = null // ì¬ìƒ ì¤‘ì¸ ë°°ê²½ìŒì•…ì˜ Howl ID
  private currentBackgroundMusicId: number | null = null
  private previewMusic: Howl | null = null // ë¯¸ë¦¬ë“£ê¸°ìš© ìŒì•…
  private previewMusicId: number | null = null // ë¯¸ë¦¬ë“£ê¸° Howl ID
  private webAudioInterval: NodeJS.Timeout | null = null // Web Audio APIë¡œ ìƒì„±í•œ ìŒì•…ì˜ interval
  private webAudioContext: AudioContext | null = null // Web Audio API ì»¨í…ìŠ¤íŠ¸

  setConfig(config: Partial<AudioConfig>): void {
    const oldVolume = this.config.volume
    this.config = { ...this.config, ...config }
    
    // ë³¼ë¥¨ì´ ë³€ê²½ëœ ê²½ìš°, ì¬ìƒ ì¤‘ì¸ ëª¨ë“  ì˜¤ë””ì˜¤ì˜ ë³¼ë¥¨ ì—…ë°ì´íŠ¸
    if (config.volume !== undefined && config.volume !== oldVolume) {
      // ë°°ê²½ìŒì•… ë³¼ë¥¨ ì—…ë°ì´íŠ¸
      if (this.backgroundMusic && this.backgroundMusicId !== null) {
        try {
          // ë°°ê²½ìŒì•…ì€ ì „ì²´ ë³¼ë¥¨ì˜ 50%ë¡œ ì„¤ì •
          this.backgroundMusic.volume(config.volume * 0.5, this.backgroundMusicId)
        } catch (e) {
          console.warn('ë°°ê²½ìŒì•… ë³¼ë¥¨ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜:', e)
        }
      }
      
      // ë¯¸ë¦¬ë“£ê¸° ë³¼ë¥¨ ì—…ë°ì´íŠ¸
      if (this.previewMusic && this.previewMusicId !== null) {
        try {
          this.previewMusic.volume(config.volume * 0.5, this.previewMusicId)
        } catch (e) {
          console.warn('ë¯¸ë¦¬ë“£ê¸° ë³¼ë¥¨ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜:', e)
        }
      }
      
      // ëª¨ë“  íš¨ê³¼ìŒ ë³¼ë¥¨ ì—…ë°ì´íŠ¸
      this.sounds.forEach((sound) => {
        try {
          sound.volume(config.volume ?? 1.0)
        } catch (e) {
          console.warn('íš¨ê³¼ìŒ ë³¼ë¥¨ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜:', e)
        }
      })
      
      // Web Audio APIë¡œ ìƒì„±í•œ ë°°ê²½ìŒì•…ì˜ ê²½ìš°, config.volumeì´ ë‹¤ìŒ ìŒí‘œ ì¬ìƒ ì‹œ ì ìš©ë¨
      // (ì´ë¯¸ ì¬ìƒ ì¤‘ì¸ ìŒí‘œëŠ” ë³€ê²½í•  ìˆ˜ ì—†ì§€ë§Œ, ë‹¤ìŒ ìŒí‘œë¶€í„° ìƒˆ ë³¼ë¥¨ì´ ì ìš©ë¨)
    }
  }

  getConfig(): AudioConfig {
    return { ...this.config }
  }

  // ìŒì„± í•©ì„± (TTS)
  speak(text: string): void {
    console.log('ğŸ”Š audioService.speak() í˜¸ì¶œ:', { text, enabled: this.config.enabled, volume: this.config.volume, voiceType: this.config.voiceType })
    
    if (!this.config.enabled) {
      console.warn('âš ï¸ ìŒì„± ì¶œë ¥ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.')
      return
    }

    if ('speechSynthesis' in window) {
      console.log('âœ… speechSynthesis ì§€ì› í™•ì¸ë¨')
      // ì´ì „ ìŒì„± ì·¨ì†Œ (ì¤‘ë³µ ë°©ì§€)
      speechSynthesis.cancel()
      
      const utterance = new SpeechSynthesisUtterance(text)
      utterance.lang = 'ko-KR'
      utterance.volume = this.config.volume
      
      // ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ì¶”ê°€ (ë””ë²„ê¹…ìš©)
      utterance.onstart = () => {
        console.log('âœ… ìŒì„± ì¶œë ¥ ì‹œì‘:', text)
      }
      utterance.onend = () => {
        console.log('âœ… ìŒì„± ì¶œë ¥ ì™„ë£Œ:', text)
      }
      utterance.onerror = (event) => {
        // interrupted ì—ëŸ¬ëŠ” ì •ìƒì ì¸ ë™ì‘ (ì´ì „ ìŒì„±ì„ ì·¨ì†Œí•˜ê³  ìƒˆ ìŒì„±ì„ ì¬ìƒí•˜ê¸° ë•Œë¬¸)
        if (event.error === 'interrupted') {
          console.log('â„¹ï¸ ìŒì„± ì¶œë ¥ ì¤‘ë‹¨ë¨ (ì •ìƒ):', text)
        } else {
          console.error('âŒ ìŒì„± ì¶œë ¥ ì˜¤ë¥˜:', event.error, text)
        }
      }
      
      // ìŒì„± íƒ€ì… ì„¤ì • (ë” ì •í™•í•œ ë§¤ì¹­)
      const setVoice = () => {
        const voices = speechSynthesis.getVoices()
        console.log('ğŸ” ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„± ëª©ë¡:', voices.length, 'ê°œ')
        
        if (voices.length === 0) {
          // voicesê°€ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì¬ì‹œë„
          console.log('â³ ìŒì„± ëª©ë¡ ë¡œë”© ì¤‘... ì¬ì‹œë„ ì˜ˆì •')
          setTimeout(setVoice, 100)
          return
        }
        
        // í•œêµ­ì–´ ìŒì„± ëª©ë¡ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
        const koreanVoices = voices.filter(v => v.lang.startsWith('ko'))
        console.log('ğŸ‡°ğŸ‡· í•œêµ­ì–´ ìŒì„± ëª©ë¡:', koreanVoices.map(v => ({ name: v.name, lang: v.lang, default: v.default })))
        
        let koreanVoice = null
        
        if (this.config.voiceType === 'male') {
          // ë‚¨ì„± ìŒì„± ì°¾ê¸° (ì—¬ëŸ¬ íŒ¨í„´ ì‹œë„)
          koreanVoice = voices.find((voice) => 
            voice.lang.startsWith('ko') && (
              voice.name.includes('ë‚¨') || 
              voice.name.includes('Male') || 
              voice.name.includes('male') ||
              voice.name.toLowerCase().includes('yuna') === false // YunaëŠ” ì—¬ì„±
            )
          ) || voices.find((voice) => voice.lang.startsWith('ko'))
        } else {
          // ì—¬ì„± ìŒì„± ì°¾ê¸°
          koreanVoice = voices.find((voice) => 
            voice.lang.startsWith('ko') && (
              voice.name.includes('ì—¬') || 
              voice.name.includes('Female') || 
              voice.name.includes('female') ||
              voice.name.includes('Yuna')
            )
          ) || voices.find((voice) => voice.lang.startsWith('ko'))
        }
        
        if (koreanVoice) {
          utterance.voice = koreanVoice
          console.log('âœ… ì„ íƒëœ ìŒì„±:', koreanVoice.name, koreanVoice.lang)
        } else {
          console.warn('âš ï¸ í•œêµ­ì–´ ìŒì„±ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ìŒì„± ì‚¬ìš©')
        }
        
        console.log('ğŸ¤ speechSynthesis.speak() í˜¸ì¶œ:', { text, voice: koreanVoice?.name, volume: utterance.volume })
        speechSynthesis.speak(utterance)
      }
      
      // voices ë¡œë“œ ëŒ€ê¸°
      if (speechSynthesis.getVoices().length === 0) {
        console.log('â³ ìŒì„± ëª©ë¡ ë¡œë”© ëŒ€ê¸° ì¤‘... onvoiceschanged ì´ë²¤íŠ¸ ëŒ€ê¸°')
        speechSynthesis.onvoiceschanged = setVoice
      } else {
        setVoice()
      }
    } else {
      console.error('âŒ speechSynthesisê°€ ì§€ì›ë˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤.')
    }
  }

  // íš¨ê³¼ìŒ ì¬ìƒ
  playSound(soundName: string, volume?: number): void {
    if (!this.config.enabled) return

    const sound = this.sounds.get(soundName)
    if (sound) {
      sound.volume(volume ?? this.config.volume)
      sound.play()
    }
  }

  // íš¨ê³¼ìŒ ë¡œë“œ
  loadSound(name: string, src: string): void {
    const sound = new Howl({
      src: [src],
      volume: this.config.volume,
    })
    this.sounds.set(name, sound)
  }

  stopAll(): void {
    // ë°°ê²½ìŒì•… ë¨¼ì € ì •ì§€ (ê°€ì¥ ì¤‘ìš”)
    this.stopBackgroundMusic()
    
    // ë¯¸ë¦¬ë“£ê¸° ì •ì§€
    this.stopPreview()
    
    // ëª¨ë“  íš¨ê³¼ìŒ ì •ì§€
    this.sounds.forEach((sound) => {
      try {
        sound.stop()
        sound.unload()
      } catch (e) {
        console.warn('íš¨ê³¼ìŒ ì •ì§€ ì¤‘ ì˜¤ë¥˜:', e)
      }
    })
    this.sounds.clear()
    
    // ìŒì„± í•©ì„± ì·¨ì†Œ
    speechSynthesis.cancel()
    
    // ì¶”ê°€ ì•ˆì „ì¥ì¹˜: ëª¨ë“  Howl ì¸ìŠ¤í„´ìŠ¤ ê°•ì œ ì •ì§€
    try {
      // Howlì˜ ëª¨ë“  ì¬ìƒ ì¤‘ì¸ ì‚¬ìš´ë“œ ê°•ì œ ì •ì§€
      if (typeof window !== 'undefined' && (window as any).Howl) {
        const HowlClass = (window as any).Howl
        // Howlì˜ ë‚´ë¶€ ì¸ìŠ¤í„´ìŠ¤ ëª©ë¡ì— ì ‘ê·¼í•˜ì—¬ ëª¨ë‘ ì •ì§€
        if (HowlClass._howls && Array.isArray(HowlClass._howls)) {
          HowlClass._howls.forEach((howl: any) => {
            try {
              if (howl && typeof howl.stop === 'function') {
                howl.stop()
              }
              if (howl && typeof howl.unload === 'function') {
                howl.unload()
              }
            } catch (e) {
              // ê°œë³„ ì¸ìŠ¤í„´ìŠ¤ ì •ì§€ ì‹¤íŒ¨ëŠ” ë¬´ì‹œ
            }
          })
          // ì¸ìŠ¤í„´ìŠ¤ ëª©ë¡ ì´ˆê¸°í™”
          HowlClass._howls = []
        }
      }
    } catch (e) {
      console.warn('ì „ì—­ ì˜¤ë””ì˜¤ ì •ì§€ ì¤‘ ì˜¤ë¥˜:', e)
    }
  }

  // ë°°ê²½ìŒì•… ì¬ìƒ
  playBackgroundMusic(musicId: number = 1, preview: boolean = false): void {
    if (!this.config.enabled && !preview) return

    // ë¯¸ë¦¬ë“£ê¸°ì¸ ê²½ìš° ê¸°ì¡´ ë¯¸ë¦¬ë“£ê¸° ì •ì§€
    if (preview) {
      this.stopPreview()
    }

    // ê¸°ì¡´ ë°°ê²½ìŒì•… ì •ì§€ (ë¯¸ë¦¬ë“£ê¸°ê°€ ì•„ë‹ ë•Œë§Œ)
    if (!preview) {
      // ê°•ì œë¡œ ëª¨ë“  ë°°ê²½ìŒì•… ì •ì§€
      this.stopBackgroundMusic()
    }

    // ë°°ê²½ìŒì•… íŒŒì¼ ê²½ë¡œ (bgm í´ë”ì— ìˆìŒ)
    const musicFiles = [
      '/bgm/bgm1.mp3', // í™œê¸°ì°¬ ê²Œì„ ìŒì•…
      '/bgm/bgm2.mp3', // ë™ê¸°ë¶€ì—¬ ìŒì•…
      '/bgm/bgm3.mp3', // ì—ë„ˆì§€ ë„˜ì¹˜ëŠ” ìŒì•…
      '/bgm/bgm4.mp3', // ì¬ë¯¸ìˆëŠ” ìŒì•…
      '/bgm/bgm5.mp3', // í˜ì°¬ ìŒì•…
      '/bgm/bgm6.mp3', // ì¶”ê°€ ë°°ê²½ìŒì•…
    ]

    if (musicId >= 1 && musicId <= 6) {
      const music = new Howl({
        src: [musicFiles[musicId - 1]],
        loop: !preview, // ë¯¸ë¦¬ë“£ê¸°ëŠ” ë°˜ë³µ ì•ˆí•¨
        volume: this.config.volume * 0.5, // ë°°ê²½ìŒì•…ì€ ì¡°ê¸ˆ ë‚®ê²Œ
        html5: true, // HTML5 ì˜¤ë””ì˜¤ ì‚¬ìš©
        onloaderror: () => {
          // íŒŒì¼ì´ ì—†ìœ¼ë©´ Web Audio APIë¡œ ê°„ë‹¨í•œ ë°°ê²½ìŒì•… ìƒì„±
          console.warn(`ë°°ê²½ìŒì•… íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ${musicFiles[musicId - 1]}, Web Audio APIë¡œ ìƒì„±í•©ë‹ˆë‹¤.`)
          this.createBackgroundMusicWithWebAudio(musicId, preview)
        },
        onload: () => {
          // íŒŒì¼ ë¡œë“œ ì„±ê³µ
          // ëª¨ë°”ì¼ í™˜ê²½ì—ì„œ AudioContextê°€ suspended ìƒíƒœì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ resume ì²˜ë¦¬
          const resumeAudioContext = async () => {
            try {
              // Howlì´ ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” AudioContextì— ì ‘ê·¼
              const howlContext = (music as any)._sounds?.[0]?._node?.context
              if (howlContext && howlContext.state === 'suspended') {
                await howlContext.resume()
                console.log('AudioContext resumed for background music')
              }
            } catch (e) {
              console.warn('AudioContext resume ì‹¤íŒ¨:', e)
            }
          }

          if (preview) {
            // ë¯¸ë¦¬ë“£ê¸°ëŠ” 5ì´ˆ ì¬ìƒ í›„ ì •ì§€
            this.previewMusic = music
            resumeAudioContext().then(() => {
              const id = music.play()
              this.previewMusicId = id
              setTimeout(() => {
                if (this.previewMusic === music && this.previewMusicId === id) {
                  music.stop(id)
                  this.previewMusic = null
                  this.previewMusicId = null
                }
              }, 5000)
            }).catch((e) => {
              console.warn('ë¯¸ë¦¬ë“£ê¸° ì¬ìƒ ì‹¤íŒ¨:', e)
              // ì‹¤íŒ¨í•´ë„ ì¬ìƒ ì‹œë„
              const id = music.play()
              this.previewMusicId = id
            })
          } else {
            this.backgroundMusic = music
            this.currentBackgroundMusicId = musicId
            resumeAudioContext().then(() => {
              const id = music.play()
              this.backgroundMusicId = id
            }).catch((e) => {
              console.warn('ë°°ê²½ìŒì•… ì¬ìƒ ì‹¤íŒ¨:', e)
              // ì‹¤íŒ¨í•´ë„ ì¬ìƒ ì‹œë„
              const id = music.play()
              this.backgroundMusicId = id
            })
          }
        },
      })

      // ë¡œë“œ ì‹œì‘ (íŒŒì¼ì´ ì—†ì–´ë„ ì‹œë„)
      try {
        music.load()
      } catch (e) {
        // ë¡œë“œ ì‹¤íŒ¨ ì‹œ Web Audio APIë¡œ ìƒì„±
        console.warn('ë°°ê²½ìŒì•… ë¡œë“œ ì‹¤íŒ¨, Web Audio APIë¡œ ìƒì„±í•©ë‹ˆë‹¤.')
        this.createBackgroundMusicWithWebAudio(musicId, preview)
      }
    }
  }

  // Web Audio APIë¡œ ë°°ê²½ìŒì•… ìƒì„± (íŒŒì¼ì´ ì—†ì„ ë•Œ)
  private createBackgroundMusicWithWebAudio(musicId: number, preview: boolean): void {
    try {
      // ê¸°ì¡´ Web Audio ì •ì§€
      if (this.webAudioInterval) {
        clearInterval(this.webAudioInterval)
        this.webAudioInterval = null
      }
      if (this.webAudioContext) {
        this.webAudioContext.close().catch(() => {})
      }
      
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)()
      this.webAudioContext = audioContext
      
      // ëª¨ë°”ì¼ í™˜ê²½ì—ì„œ AudioContextê°€ suspended ìƒíƒœì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ resume ì²˜ë¦¬
      if (audioContext.state === 'suspended') {
        audioContext.resume().then(() => {
          console.log('Web Audio Context resumed for background music')
        }).catch((e) => {
          console.warn('Web Audio Context resume ì‹¤íŒ¨:', e)
        })
      }
      
      // ë” ì™„ì „í•œ ë©œë¡œë”” ìƒì„± (ê° ìŒì•…ë§ˆë‹¤ ë‹¤ë¥¸ íŒ¨í„´ê³¼ ë¦¬ë“¬)
      const musicPatterns = [
        // 1ë²ˆ: í™œê¸°ì°¬ ê²Œì„ ìŒì•… (C major scale ê¸°ë°˜)
        {
          melody: [261.63, 293.66, 329.63, 349.23, 392.00, 440.00, 493.88, 523.25], // C, D, E, F, G, A, B, C
          rhythm: [0.3, 0.2, 0.3, 0.2, 0.3, 0.2, 0.3, 0.4], // ê° ìŒì˜ ê¸¸ì´
          tempo: 400, // ë°€ë¦¬ì´ˆ
        },
        // 2ë²ˆ: ë™ê¸°ë¶€ì—¬ ìŒì•… (A minor scale)
        {
          melody: [220.00, 246.94, 261.63, 293.66, 329.63, 349.23, 392.00, 440.00], // A, B, C, D, E, F, G, A
          rhythm: [0.4, 0.3, 0.4, 0.3, 0.4, 0.3, 0.4, 0.5],
          tempo: 450,
        },
        // 3ë²ˆ: ì—ë„ˆì§€ ë„˜ì¹˜ëŠ” ìŒì•… (E major scale)
        {
          melody: [329.63, 369.99, 415.30, 466.16, 523.25, 587.33, 659.25, 698.46], // E, F#, G#, A, B, C#, D#, E
          rhythm: [0.25, 0.25, 0.3, 0.25, 0.25, 0.3, 0.25, 0.4],
          tempo: 350,
        },
        // 4ë²ˆ: ì¬ë¯¸ìˆëŠ” ìŒì•… (G major scale)
        {
          melody: [392.00, 440.00, 493.88, 523.25, 587.33, 659.25, 739.99, 783.99], // G, A, B, C, D, E, F#, G
          rhythm: [0.3, 0.2, 0.3, 0.2, 0.3, 0.2, 0.3, 0.4],
          tempo: 380,
        },
        // 5ë²ˆ: í˜ì°¬ ìŒì•… (D major scale)
        {
          melody: [293.66, 329.63, 369.99, 392.00, 440.00, 493.88, 554.37, 587.33], // D, E, F#, G, A, B, C#, D
          rhythm: [0.35, 0.3, 0.35, 0.3, 0.35, 0.3, 0.35, 0.5],
          tempo: 420,
        },
        // 6ë²ˆ: ì¶”ê°€ ë°°ê²½ìŒì•… (F major scale)
        {
          melody: [349.23, 392.00, 440.00, 466.16, 523.25, 587.33, 659.25, 698.46], // F, G, A, A#, B, C, D, E
          rhythm: [0.3, 0.25, 0.3, 0.25, 0.3, 0.25, 0.3, 0.4],
          tempo: 400,
        },
      ]

      const pattern = musicPatterns[musicId - 1]
      let noteIndex = 0
      let beatCount = 0

      const playNote = () => {
        if (noteIndex >= pattern.melody.length) {
          noteIndex = 0
          beatCount++
          if (preview && beatCount >= 2) {
            // ë¯¸ë¦¬ë“£ê¸°ëŠ” 2ë°”í€´ë§Œ
            if (this.webAudioInterval) {
              clearInterval(this.webAudioInterval)
              this.webAudioInterval = null
            }
            return
          }
        }

        const freq = pattern.melody[noteIndex]
        const duration = pattern.rhythm[noteIndex]

        // ë©”ì¸ ë©œë¡œë””
        const oscillator1 = audioContext.createOscillator()
        const gainNode1 = audioContext.createGain()

        oscillator1.connect(gainNode1)
        gainNode1.connect(audioContext.destination)

        oscillator1.frequency.value = freq
        oscillator1.type = 'sine'
        gainNode1.gain.setValueAtTime(0.08 * this.config.volume, audioContext.currentTime)
        gainNode1.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + duration)

        oscillator1.start(audioContext.currentTime)
        oscillator1.stop(audioContext.currentTime + duration)

        // í•˜ëª¨ë‹ˆ ì¶”ê°€ (ì˜¥íƒ€ë¸Œ ì•„ë˜)
        if (noteIndex % 2 === 0) {
          const oscillator2 = audioContext.createOscillator()
          const gainNode2 = audioContext.createGain()

          oscillator2.connect(gainNode2)
          gainNode2.connect(audioContext.destination)

          oscillator2.frequency.value = freq * 0.5
          oscillator2.type = 'triangle'
          gainNode2.gain.setValueAtTime(0.03 * this.config.volume, audioContext.currentTime)
          gainNode2.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + duration)

          oscillator2.start(audioContext.currentTime)
          oscillator2.stop(audioContext.currentTime + duration)
        }

        noteIndex++
      }

      // ì²« ìŒ ì¬ìƒ
      playNote()

      // ë°˜ë³µ ì¬ìƒ (ë¯¸ë¦¬ë“£ê¸°ê°€ ì•„ë‹ ë•Œë§Œ)
      if (!preview) {
        this.webAudioInterval = setInterval(playNote, pattern.tempo)
      } else {
        // ë¯¸ë¦¬ë“£ê¸°ëŠ” 5ì´ˆ í›„ ì •ì§€ (ë” ê¸¸ê²Œ)
        this.webAudioInterval = setInterval(playNote, pattern.tempo)
        setTimeout(() => {
          if (this.webAudioInterval) {
            clearInterval(this.webAudioInterval)
            this.webAudioInterval = null
          }
        }, 5000)
      }
    } catch (e) {
      console.error('Web Audio APIë¡œ ë°°ê²½ìŒì•… ìƒì„± ì‹¤íŒ¨:', e)
    }
  }

  // ë°°ê²½ìŒì•… ì •ì§€
  stopBackgroundMusic(): void {
    // Howl ì¸ìŠ¤í„´ìŠ¤ê°€ ìˆìœ¼ë©´ ê°•ì œë¡œ ì •ì§€
    if (this.backgroundMusic) {
      try {
        // ëª¨ë“  ì¬ìƒ ì¤‘ì¸ ì‚¬ìš´ë“œ ì •ì§€
        if (this.backgroundMusicId !== null) {
          this.backgroundMusic.stop(this.backgroundMusicId)
        }
        // ëª¨ë“  ì¬ìƒ ì¤‘ì¸ ì‚¬ìš´ë“œ ê°•ì œ ì •ì§€ (ì•ˆì „ì¥ì¹˜)
        this.backgroundMusic.stop()
        
        // ë¦¬ì†ŒìŠ¤ í•´ì œ
        this.backgroundMusic.unload()
      } catch (e) {
        console.warn('ë°°ê²½ìŒì•… ì •ì§€ ì¤‘ ì˜¤ë¥˜:', e)
      } finally {
        this.backgroundMusic = null
        this.backgroundMusicId = null
        this.currentBackgroundMusicId = null
      }
    }
    
    // Web Audio APIë¡œ ìƒì„±í•œ ìŒì•…ë„ ì •ì§€
    if (this.webAudioInterval) {
      clearInterval(this.webAudioInterval)
      this.webAudioInterval = null
    }
    
    if (this.webAudioContext) {
      try {
        this.webAudioContext.close().catch(() => {})
      } catch (e) {
        console.warn('Web Audio Context ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜:', e)
      } finally {
        this.webAudioContext = null
      }
    }
  }

  // ë¯¸ë¦¬ë“£ê¸° ì •ì§€
  stopPreview(): void {
    if (this.previewMusic) {
      // ëª¨ë“  ì¬ìƒ ì¤‘ì¸ ë¯¸ë¦¬ë“£ê¸° ì •ì§€
      if (this.previewMusicId !== null) {
        this.previewMusic.stop(this.previewMusicId)
      } else {
        this.previewMusic.stop()
      }
      this.previewMusic.unload() // ë¦¬ì†ŒìŠ¤ í•´ì œ
      this.previewMusic = null
      this.previewMusicId = null
    }
  }

  // ë°°ê²½ìŒì•… ì¼ì‹œì •ì§€
  pauseBackgroundMusic(): void {
    if (this.backgroundMusic) {
      this.backgroundMusic.pause()
    }
  }

  // ë°°ê²½ìŒì•… ì¬ê°œ
  resumeBackgroundMusic(): void {
    if (this.backgroundMusic) {
      this.backgroundMusic.play()
    }
  }

  // ì¹´ìš´íŠ¸ ì‚¬ìš´ë“œ (ë”©ë™)
  playCountSound(count: number): void {
    if (!this.config.enabled) return

    // ë”©ë™ ì‚¬ìš´ë“œ (ê°„ë‹¨í•œ beep ì‚¬ìš´ë“œ)
    // ì‹¤ì œë¡œëŠ” ì˜¤ë””ì˜¤ íŒŒì¼ì´ í•„ìš”í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” Web Audio APIë¡œ ìƒì„±
    const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)()
    
    // ëª¨ë°”ì¼ í™˜ê²½ì—ì„œ AudioContextê°€ suspended ìƒíƒœì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ resume ì²˜ë¦¬
    if (audioContext.state === 'suspended') {
      audioContext.resume().catch((e) => {
        console.warn('AudioContext resume ì‹¤íŒ¨:', e)
      })
    }
    const oscillator = audioContext.createOscillator()
    const gainNode = audioContext.createGain()

    oscillator.connect(gainNode)
    gainNode.connect(audioContext.destination)

    oscillator.frequency.value = 800 + (count * 50) // ì¹´ìš´íŠ¸ì— ë”°ë¼ í”¼ì¹˜ ì¦ê°€
    oscillator.type = 'sine'
    gainNode.gain.setValueAtTime(0.3, audioContext.currentTime)
    gainNode.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + 0.2)

    oscillator.start(audioContext.currentTime)
    oscillator.stop(audioContext.currentTime + 0.2)
  }

  // íŒ¡íŒŒë ˆ ì‚¬ìš´ë“œ (ë§ˆì§€ë§‰ ê°¯ìˆ˜)
  playFanfareSound(): void {
    if (!this.config.enabled) return

    // íŒ¡íŒŒë ˆ ì‚¬ìš´ë“œ (ì—¬ëŸ¬ ìŒì„ ì—°ì†ìœ¼ë¡œ)
    const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)()
    
    // ëª¨ë°”ì¼ í™˜ê²½ì—ì„œ AudioContextê°€ suspended ìƒíƒœì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ resume ì²˜ë¦¬
    if (audioContext.state === 'suspended') {
      audioContext.resume().catch((e) => {
        console.warn('AudioContext resume ì‹¤íŒ¨:', e)
      })
    }
    const notes = [523.25, 659.25, 783.99, 1046.50] // C, E, G, C (ë„ë¯¸ì†”ë„)

    notes.forEach((freq, index) => {
      setTimeout(() => {
        const oscillator = audioContext.createOscillator()
        const gainNode = audioContext.createGain()

        oscillator.connect(gainNode)
        gainNode.connect(audioContext.destination)

        oscillator.frequency.value = freq
        oscillator.type = 'sine'
        gainNode.gain.setValueAtTime(0.3, audioContext.currentTime)
        gainNode.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + 0.3)

        oscillator.start(audioContext.currentTime)
        oscillator.stop(audioContext.currentTime + 0.3)
      }, index * 150)
    })
  }

  // ì—ë„ˆì§€ íš¨ê³¼ìŒ
  playEnergySound(): void {
    if (!this.config.enabled) return

    // ì—ë„ˆì§€ê°€ ì°¨ì˜¤ë¥´ëŠ” ë“¯í•œ íš¨ê³¼ìŒ
    const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)()
    
    // ëª¨ë°”ì¼ í™˜ê²½ì—ì„œ AudioContextê°€ suspended ìƒíƒœì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ resume ì²˜ë¦¬
    if (audioContext.state === 'suspended') {
      audioContext.resume().catch((e) => {
        console.warn('AudioContext resume ì‹¤íŒ¨:', e)
      })
    }
    const oscillator = audioContext.createOscillator()
    const gainNode = audioContext.createGain()

    oscillator.connect(gainNode)
    gainNode.connect(audioContext.destination)

    oscillator.frequency.setValueAtTime(200, audioContext.currentTime)
    oscillator.frequency.exponentialRampToValueAtTime(800, audioContext.currentTime + 0.5)
    oscillator.type = 'sawtooth'
    gainNode.gain.setValueAtTime(0, audioContext.currentTime)
    gainNode.gain.linearRampToValueAtTime(0.5, audioContext.currentTime + 0.1)
    gainNode.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + 0.5)

    oscillator.start(audioContext.currentTime)
    oscillator.stop(audioContext.currentTime + 0.5)
  }
}

export const audioService = new AudioService()

